\section{The algortihm C2-AS-FI}
\label{sec:C2-AS-FI}

The most expensive step of C2-AS is the polynomial interpolation step
which is part of the Cauchy interpolation. If we use a standard
interpolation algorithm, its input consists in a list of $\Theta(p^k)$
pairs $\bigl(P, \I(P)\bigr)$ with $P\in\U_k$, thus a lower bound for
any such algorithm is $\Omega(p^{2k}d)$. Notice however that the
output is a polynomial of degree $\Theta(p^k)$ in $\F_q[X]$, hence, if
supplied with a shorter input, an \emph{ad hoc} algorithm could reach
the bound $\Omega(p^kd)$.

In this section we give an algorithm that reaches this bound up to
some logarithmic factors. It realizes the polynomial interpolation on
the primitive points of $E[p^k]$, thus its output is a degree
$\euler(p^k)/2-1$ polynomial in $\F_q[X]$. Using the Chinese remainder
theorem, it is straightforward to generalise this to an algorithm
having the same asymptotic complexity realizing the polynomial
interpolation on all the points of $E[p^k]$. We call C2-AS-FI the
variant of C2-AS resulting from applying this new algorithm.

\subsection{The algorithm}
We set some notation. Let $i_0$ be the largest index such that
$\U_{i_0} = \U_1$ and let $\frac{p-1}{2r} = [\F_q[c^2]:\F_q]$. For
notational convenience, we set $\U_0=\F_q$.

We note $T(X)$ the polynomial vanishing on the primitive points of
$E[p^k]$ and

\begin{equation}
  \label{eq:T}
  T = \prod T_j^{(i)}
\end{equation}
its factorisation over $\U_i$; we remark that all the $T_j^{(0)}$'s
have degree $\frac{\euler(p^{k-i_0+1})}{2r}$. We also note $A(X)$ the goal
polynomial and
\begin{equation}
  \label{eq:A}
  A_j^{(i)} = A \bmod T_j^{(i)}
  \;\text{.}
\end{equation}

It was already pointed out in \cite[$\S$2.3]{Cou96} that if all the
$A_j^{(0)}$'s are known one can recover $A$ using the Chinese remainder
theorem. If we chose any point $P$ such that
$T_j^{(0)}\bigl(x(P)\bigr)=0$ and fix the embedding
\begin{equation}
  \label{eq:embed}
  \xymatrix{
    ^{\F_q[X]}/_{T_j^{(0)}(X)} \ar@{^{(}->}[r]^-\iota & \U_k
  }
\end{equation}
given by $\iota(X) = x(P)$, then it is evident that
$\iota\bigl(A_j^{(0)}(X)\bigr) = x\bigl(\I(P)\bigr)$, thus in order to
compute $A_j^{(0)}$ one just needs to compute
$\iota^{-1}\bigl(x(\I(P))\bigr)$.

Unfortunately, the information needed to compute $\iota$ was lost in
the $p$-descent, for we don't even know the $T_j^{(i)}$'s. None of the
algorithms of \cite{DFS09} helps us to compute such information and
straightforward computation of it would be too expensive. The solution
is to decompose $\iota$ as a chain of morphisms and invert them
one-by-one going down in the tower $(\U_0,\U_1,\ldots,\U_k)$, this is
similar to the way \cite{Cou00} solves an Artin-Schreier equation by
moving it down from $\U_k$ to $\U_1$.

\paragraph{The moduli}
We first need to compute $T_0^{(i)}\in\U_i[X]$ for any $i$. For this
we fix a primitive point $P\in E[p^k]$ and we reorder the indices in
\eqref{eq:T} so that $T_0^{(i)}$ is the minimal polynomial of $x(P)$
over $\U_i$.

The first minimal polynomial is simply
\begin{equation}
  \label{eq:T_0^k}
  T_0^{(k)}(X) = X - x(P)
  \;\text{.}
\end{equation}
Now suppose we know $T_0^{(i+1)}$, then a generator $\sigma$ of
$\Gal(\U_{i+1}/\U_i)$ acts on the roots of $T_0^{(i+1)}$ sending them
on the roots of some $T_j^{(i+1)}$. Then the
minimal polynomial of $x(P)$ over $\U_i$ is
\begin{equation}
  \label{eq:T_0^i}
  T_0^{(i)} = \prod_{\sigma\in\Gal(\U_{i+1}/\U_i)} \sigma\left(T_0^{(i+1)}\right)
  \;\text{.}
\end{equation}
Some care has to be taken when computing $T_0^{(0)}$: in fact the
abscissae of the points may be counted twice if
$c\not\in\F_q[c^2]$. In this case only a subgroup of index $2$ of
$\Gal(\U_1/\U_0)$ must be used instead of the whole group.


\paragraph{The interpolation}
The computation of $A_0^{(i)}$ is done in the same recursive way. Fix
the same point $P$ used to compute the $T_0^{(i)}$'s and fix the chain
of embeddings
\begin{equation}
  \xymatrix{
    ^{\U_0[X_0]}/_{T_0^{(0)}(X_0)} \ar@{^{(}->}[r]^-{\iota_0} &
    \;\cdots\; \ar@{^{(}->}[r]^-{\iota_{k-1}} &
    ^{\U_k[X_k]}/_{T_0^{(k)}(X_k)} \ar@{^{(}->}[r]^-{\iota_k} &
    \U_k
  }
\end{equation}
given by $\iota_k\circ\cdots\circ\iota_i(X_i) = x(P)$ for any $i$.

We compute $A_0^{(i)}$ by inverting the chain: inverting $\iota_k$
simply gives
\begin{equation}
  \label{eq:A_0^k}
  A_0^{(k)} = x\bigl(\I(P)\bigr)
  \;\text{.}
\end{equation}
Then suppose we know $A_0^{(i+1)}$, and decompose the embedding
$\iota_i$ as
\begin{equation}
  \xymatrix{
    ^{\U_i[X_i]}/_{T_0^{(i)}(X_i)} \ar@{^{(}->}[r]^-{\iota_i} \ar@{^{(}->}[d]^{\varepsilon} &
    ^{\U_{i+1}[X_{i+1}]}/_{T_0^{(i+1)}(X_{i+1})} \\
    ^{\U_{i+1}[Y]}/_{T_0^{(i)}(Y)} \ar@{^{(}->>}[r]^-{\gamma} &
    \bigoplus_j {}^{\U_{i+1}[Y_{j}]}/_{T_j^{(i+1)}(Y_{j})} \ar@{->>}[u]_{\pi}
  }
\end{equation}
where $\varepsilon$ is the canonical injection extending
$\U_i\subset\U_{i+1}$, $\gamma$ is the Chinese remainder isomorphism
and $\pi$ is projection onto the first coordinate.

To invert $\pi$ observe that any $\sigma\in\Gal(\U_{i+1}/\U_i)$ leaves
$A_0^{(i)}$ invariant while it permutes the moduli $T_j^{(i+1)}$, thus
\begin{equation}
  A_0^{(i)} \equiv \sigma\left(A_0^{(i+1)}\right)
  \bmod \sigma\left(T_0^{(i+1)}\right)
  \;\text{;}
\end{equation}
Hence we can obtain all the $A_j^{(i+1)}$ through the action of
$\Gal(\U_{i+1}/\U_i)$ on $A_0^{(i+1)}$.

Then we can invert $\gamma$ through a Chinese remainder algorithm
\cite[$\S$10.3]{vzGG} and $\varepsilon$ by converting coefficients from
$\U_{i+1}$ to $\U_i$.

As for the moduli, a special treatment is needed for $\iota_0$ if
$c\not\in\F_q[c^2]$.


\subsection{Complexity analysis}
\label{sec:C2-AS-FI:complexity}

The two algorithms for computing the $T_{0}^{(i)}$'s and the
$A_{0}^{(i)}$'s are very similar and run in parallel. We can merge
them in one unique algorithm, at each level $i\ge i_0$ it does the
following

\begin{enumerate}
\item for $\sigma \in \Gal(\U_{i+1}/\U_i)$, call $\bar\sigma$ the
  permutation it induces on the indices of the $T_j^{(i+1)}$'s,
  compute
  \begin{enumerate}
  \item\label{alg:T:gal} $T_{\bar\sigma(0)}^{(i+1)} :=
    \sigma\left(T_0^{(i+1)}\right)$ and
  \item\label{alg:A:gal} $A_{\bar\sigma(0)}^{(i+1)} :=
    \sigma\left(A_0^{(i+1)}\right)$ using
    \cite[\alg{IterFrobenius}]{DFS09},
  \end{enumerate}
\item\label{alg:T:prod} compute $T_0^{(i)}$ through a subproduct tree
  as in \cite[Algo. 10.3]{vzGG},
\item\label{alg:A:CRA} compute $A_0^{(i)}$ through Chinese Reminder
  Algorithm \cite[Algo. 10.16]{vzGG},
\item\label{alg:T:push} convert $T_0^{(i)}$ and $A_0^{(i)}$ into
  elements of $\U_i[X]$ using \cite[\alg{Push-down}]{DFS09}.
\end{enumerate}

Steps \ref{alg:T:gal} and \ref{alg:A:gal} are identical. Both are
repeated $p$ times, each iteration taking $O\bigl(p^{k-i}{\sf
  L}(i-i_0)\bigr) \subset O\bigl({\sf L}(k-i_0)\bigr)$ by
\cite[Th. 17]{DFS09}.

Step \ref{alg:T:prod} takes $O\bigl(\Mult(p^{k-i_0+1}d/r)\log p\bigr)$
by \cite[Lemma 10.4]{vzGG} and step \ref{alg:A:CRA} has the same
complexity by \cite[Coro. 10.17]{vzGG}.

Step \ref{alg:T:push} takes $O\bigl(p^{k-i+1}{\sf L}(i-i_0)\bigr)
\subset O\bigl(p{\sf L}(k-i_0)\bigr)$.

When $i=0$ and $\U_1\ne\F_q$ the algorithm is identical but steps
\ref{alg:T:gal} and \ref{alg:A:gal} must be computed through a generic
frobenius algorithm (using~\cite[Algorithm 5.2]{vzGS92}, for example)
and step \ref{alg:T:push} must use the implementation of $F_q[c]$ to
make the conversion (for example, linear algebra). In this case steps
\ref{alg:T:gal} and \ref{alg:A:gal} cost
$\Theta\bigl(\frac{p^{k-i_0}}{r}\ModComp(pd)\log d \bigr)$
by~\cite[Lemma 5.3]{vzGS92} and step \ref{alg:T:push} costs
$\Theta\bigl(p^{k-i_0}(pd)^2\bigr)$.

The total cost of the algorithm is then
\begin{equation*}
  \label{eq:T:complexity}
  O\left(\bigl(k-i_0\bigr)\bigl(p{\sf L}(k-i_0) + \Mult(p^{k-i_0+1}d/r)\log p\bigr) +
    \frac{p^{k-i_0}}{r}\bigl(\ModComp(pd)\log d + r(pd)^2\bigr) \right)
  \;\text{.}
\end{equation*}

After all, the whole algorithm looks a lot like fast interpolation
\cite[$\S$10]{vzGG} and it is indeed a modified version of it. A
similar algorithm was already given in \cite{EnMo03}.


\paragraph{The complete interpolation}
We compute all the $A_j^{(0)}$'s using this algorithm; there's
$p^{i_0-1}r$ of them. We then recombine them through a Chinese
remainder algorithm at a cost of $O\bigl(\Mult(p^kd)\log
p^{i_0-1}r\bigr)$. The total cost of the whole interpolation phase is
then
\begin{equation*}
  O\left(\bigl(k-i_0\bigr) \bigl(p{\sf L}(k) + \Mult(p^kd)\log p\bigr) +
    p^{k-1}\ModComp(pd)\log d + p^{k-1}r(pd)^2 + i_0\Mult(p^kd)\log p
  \right)
  \;\text{,}
\end{equation*}
that is
\begin{equation}
  \label{eq:interp}
  O\left(p{\sf L}(k)\log\left(\frac{\ell}{p^{i_0}}\right) + 
    \Mult(\ell d)\log\ell\log p +
    \frac{\ell}{p}\ModComp(pd)\log d +
    \ell (pd)^2
  \right)
  \;\text{.}
\end{equation}

Alternatively, once $A_0^{(0)}$ is known, one could compute the other
$A_j^{(0)}$'s using modular composition with the multiplication maps
of $E$ and $E'$ as suggested in \cite{Cou96}. However this approach
doesn't give a better asymptotic complexity because in the worst case
$A_0^{(0)}=A$. From a practical point of view, though, Brent's and
Kung's algorithm for modular composition \cite{BrKu78}, despite having
a worse asymptotic complexity, could perform faster for some set of
parameters. We will discuss this matter in Section
\ref{sec:C2-AS-FI-MC}.

If more than $\euler(p^k)/2$ points are needed, but less than
$\frac{p-1}{2}$, one can use the previous algorithm to compute all the
polynomials $A_i$ interpolating respectively over the $p^i$-torsion
points of $E$ and $E'$. They can then be recombined through a Chinese
remainder algorithm at a cost of $O\bigl(\Mult(p^kd)\log p^k\bigr)$,
which doesn't change the overall complexity of C2-AS-FI.


Putting together the complexity estimates of C2-AS and C2-AS-FI, we
have the following.

\begin{theorem}
  \label{th:complexity}
  Assuming $\Mult(n) = n\log n\log\log n$, the algorithm C2-AS-FI has
  worst case complexity
  \begin{equation*}
    \tildO_{p,d,\log\ell}\left(
      p^2d^3 +
      \ModComp(p)pd +
      (pd)^\omega\log^2\ell +
      p^3\ell^2 d\log^3\ell + 
      p^2\ell^2 d^2+
      \left(\frac{\ell^2}{p} + p\right)\ModComp(pd)
    \right)
    \;\text{.}
  \end{equation*}
\end{theorem}



% Local Variables:
% mode:flyspell
% ispell-local-dictionary:"british"
% mode:TeX-PDF
% TeX-master: "ec-isogeny"
% End:
%
% LocalWords:  Schreier Artin pseudotrace frobenius bivariate Joux Sirvent FFT
% LocalWords:  Couveignes isogenies Schoof isogeny cryptosystems Lercier moduli
% LocalWords:  precomputation arithmetics polylogarithmic Karatsuba embeddings
% LocalWords:  irreducibility
